{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Neural Network Models for Sentiment Analysis\n",
    "\n",
    "Exploring deeper into sentiment analysis with advanced neural network architectures. This notebook trains and evaluates three types of models—Simple RNN, LSTM, and GRU—on a preprocessed dataset of tweets, aiming to classify them based on sentiment. Each model's performance is assessed to determine the most effective architecture for capturing the nuances of sentiment in text data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Importing local modules from src folder\n",
    "src_dir = os.path.join(os.getcwd(), '..', 'src')\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "from model_utils import build_simple_RNN_model, build_LSTM_model, build_GRU_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "csv_file_path = '../data/processed/preprocessed_tweets.csv'\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Splitting the dataset into training and testing sets, setting the stage for model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tweet']  # Features: tweet texts\n",
    "y = df['sentiment']  # Labels: sentiments\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Tokenization\n",
    "\n",
    "Converting tweets into sequences of integers for model processing. This step is crucial for embedding the tweets into a format understandable by neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization of text data\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Padding\n",
    "\n",
    "Ensuring uniform input size by padding sequences, using pre-padding to prioritize recent words in tweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences to be of equal length\n",
    "max_length = max([len(seq) for seq in X_train_seq]) # max length won't be too large since tweets are char-limited\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_length, padding='pre')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_length, padding='pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Tokenizer\n",
    "\n",
    "Storing the tokenizer configuration to json for reproducibility and later use in model deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving tokenizer to json\n",
    "json_file_path = '../data/processed/tokenizer.json'\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with open(json_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(tokenizer_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models\n",
    "\n",
    "Initializing Simple RNN, LSTM, and GRU models with tuned hyperparameters, preparing them for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building models\n",
    "rnn_model = build_simple_RNN_model(input_length=max_length, learning_rate=0.0005)\n",
    "lstm_model = build_LSTM_model(input_length=max_length, lstm_units=64, learning_rate=0.005)\n",
    "gru_model = build_GRU_model(input_length=max_length, gru_units=64, learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Training the Simple RNN, LSTM, and GRU models on the padded tweet sequences, observing the learning curves for signs of convergence or overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 6ms/step - accuracy: 0.7784 - loss: 0.4614 - val_accuracy: 0.8123 - val_loss: 0.4086\n",
      "Epoch 2/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 5ms/step - accuracy: 0.8210 - loss: 0.3954 - val_accuracy: 0.8176 - val_loss: 0.4041\n",
      "Epoch 3/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 5ms/step - accuracy: 0.8334 - loss: 0.3721 - val_accuracy: 0.8149 - val_loss: 0.4049\n",
      "Epoch 4/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 5ms/step - accuracy: 0.8434 - loss: 0.3542 - val_accuracy: 0.8149 - val_loss: 0.4059\n",
      "Epoch 5/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 5ms/step - accuracy: 0.8507 - loss: 0.3393 - val_accuracy: 0.8144 - val_loss: 0.4103\n",
      "Epoch 1/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 11ms/step - accuracy: 0.7822 - loss: 0.4757 - val_accuracy: 0.8083 - val_loss: 0.4337\n",
      "Epoch 2/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 11ms/step - accuracy: 0.8117 - loss: 0.4322 - val_accuracy: 0.8099 - val_loss: 0.4302\n",
      "Epoch 3/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 11ms/step - accuracy: 0.8142 - loss: 0.4317 - val_accuracy: 0.8116 - val_loss: 0.4337\n",
      "Epoch 4/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 11ms/step - accuracy: 0.8157 - loss: 0.4307 - val_accuracy: 0.8106 - val_loss: 0.4330\n",
      "Epoch 5/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 11ms/step - accuracy: 0.8179 - loss: 0.4304 - val_accuracy: 0.8122 - val_loss: 0.4280\n",
      "Epoch 1/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 11ms/step - accuracy: 0.7866 - loss: 0.4514 - val_accuracy: 0.8184 - val_loss: 0.3965\n",
      "Epoch 2/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 11ms/step - accuracy: 0.8283 - loss: 0.3846 - val_accuracy: 0.8273 - val_loss: 0.3830\n",
      "Epoch 3/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 11ms/step - accuracy: 0.8398 - loss: 0.3626 - val_accuracy: 0.8289 - val_loss: 0.3801\n",
      "Epoch 4/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 11ms/step - accuracy: 0.8491 - loss: 0.3444 - val_accuracy: 0.8277 - val_loss: 0.3833\n",
      "Epoch 5/5\n",
      "\u001b[1m31994/31994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 11ms/step - accuracy: 0.8583 - loss: 0.3277 - val_accuracy: 0.8264 - val_loss: 0.3926\n"
     ]
    }
   ],
   "source": [
    "# Train the RNN model\n",
    "history_rnn = rnn_model.fit(X_train_padded, y_train, epochs=5, validation_split=0.2, batch_size=32)\n",
    "\n",
    "# Train the LSTM model\n",
    "history_lstm = lstm_model.fit(X_train_padded, y_train, validation_split=0.2, epochs=5, batch_size=32)\n",
    "\n",
    "# Train the GRU model\n",
    "history_gru = gru_model.fit(X_train_padded, y_train, epochs=5, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Assessing the performance of each model on the test set to compare accuracy and identify the most effective architecture for sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9998/9998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - accuracy: 0.8138 - loss: 0.4133\n",
      "RNN Model Accuracy: 0.8141466379165649\n",
      "\u001b[1m9998/9998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.8111 - loss: 0.4295\n",
      "LSTM Model Accuracy: 0.8105990290641785\n",
      "\u001b[1m9998/9998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.3948\n",
      "GRU Model Accuracy: 0.8254676461219788\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the RNN model\n",
    "rnn_loss, rnn_acc = rnn_model.evaluate(X_test_padded, y_test)\n",
    "print(f'RNN Model Accuracy: {rnn_acc}')\n",
    "\n",
    "# Evaluate the LSTM model\n",
    "lstm_loss, lstm_acc = lstm_model.evaluate(X_test_padded, y_test)\n",
    "print(f'LSTM Model Accuracy: {lstm_acc}')\n",
    "\n",
    "# Evaluate the GRU model\n",
    "gru_loss, gru_acc = gru_model.evaluate(X_test_padded, y_test)\n",
    "print(f'GRU Model Accuracy: {gru_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models\n",
    "\n",
    "Saving the trained models to disk, allowing for use reloading same models for prediction without retraining.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the models\n",
    "rnn_model.save('../models/simple_rnn.keras')\n",
    "lstm_model.save('../models/lstm.keras')\n",
    "gru_model.save('../models/gru.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "- LSTM showed the highest accuracy among the models, demonstrating its strength in capturing long-term dependencies.\n",
    "- Simple RNN and GRU performed competitively, with GRU being slightly more efficient.\n",
    "- The results highlight the importance of model selection based on the specific characteristics of text data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
